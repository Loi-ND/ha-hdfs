services:
    zookeeper-1:
        image: loind31/zookeeper:v0
        hostname: zookeeper-1
        container_name: zookeeper-1
        ports:
            - 2181:2181
        environment:
            ZK_ID: 1
        command: ["/bin/bash", "/workspace/entrypoint.sh"]
        volumes:
            - ./config/zookeeper:/workspace/zookeeper/conf
            - ./data/zookeepers/node-1:/workspace/zookeeper/data
            - ./scripts/zookeeper-entrypoint.sh:/workspace/entrypoint.sh
    
    zookeeper-2:
        image: loind31/zookeeper:v0
        hostname: zookeeper-2
        container_name: zookeeper-2
        ports:
            - 2182:2181
        environment:
            ZK_ID: 2
        command: ["/bin/bash", "/workspace/entrypoint.sh"]
        volumes:
            - ./config/zookeeper:/workspace/zookeeper/conf
            - ./data/zookeepers/node-2:/workspace/zookeeper/data
            - ./scripts/zookeeper-entrypoint.sh:/workspace/entrypoint.sh
        
    zookeeper-3:
        image: loind31/zookeeper:v0
        hostname: zookeeper-3
        container_name: zookeeper-3
        ports:
            - 2183:2181
        environment:
            ZK_ID: 3
        command: ["/bin/bash", "/workspace/entrypoint.sh"]
        volumes:
            - ./config/zookeeper:/workspace/zookeeper/conf
            - ./data/zookeepers/node-3:/workspace/zookeeper/data
            - ./scripts/zookeeper-entrypoint.sh:/workspace/entrypoint.sh

    namenode1:
        image: loind31/hdfs-spark:v0
        hostname: namenode1
        container_name: namenode1
        command: ["/bin/bash", "/workspace/actived-namenode.sh"]
        environment:
            NAMENODE_ROLE: "active"
        ports:
            - 8088:8088
            - 19888:19888
            - 9870:9870
            - 8888:8888
            - 18080:18080
            - 15002:15002
            - 4040:4040
        volumes:
            - ./data/namenodes/actived:/workspace/hadoop/dfs/name
            - ./config/hdfs-spark/spark-defaults.conf:/workspace/spark/conf/spark-defaults.conf
            - ./config/hdfs-spark/common/hdfs-site.xml:/workspace/hadoop/etc/hadoop/hdfs-site.xml
            - ./config/hdfs-spark/common/core-site.xml:/workspace/hadoop/etc/hadoop/core-site.xml
            - ./config/hdfs-spark/common/mapred-site.xml:/workspace/hadoop/etc/hadoop/mapred-site.xml
            - ./config/hdfs-spark/common/yarn-site.xml:/workspace/hadoop/etc/hadoop/yarn-site.xml
            - ./src:/workspace/src
            - ./scripts/namenode-entrypoint.sh:/workspace/actived-namenode.sh
        depends_on:
            - datanode-nodemanager-1
            - datanode-nodemanager-2
            - datanode-nodemanager-3
    
    namenode2:
        image: loind31/hdfs-spark:v0
        hostname: namenode2
        container_name: namenode2
        command: ["/bin/bash", "/workspace/standby-namenode.sh"]
        environment:
            NAMENODE_ROLE: "standby"
        ports:
            - 8089:8088
            - 19889:19888
            - 9871:9870
            - 8889:8888
            - 18081:18080
            - 15003:15002
            - 4041:4040
        volumes:
            - ./data/namenodes/standby:/workspace/hadoop/dfs/name
            - ./config/hdfs-spark/spark-defaults.conf:/workspace/spark/conf/spark-defaults.conf
            - ./config/hdfs-spark/common/hdfs-site.xml:/workspace/hadoop/etc/hadoop/hdfs-site.xml
            - ./config/hdfs-spark/common/core-site.xml:/workspace/hadoop/etc/hadoop/core-site.xml
            - ./config/hdfs-spark/common/mapred-site.xml:/workspace/hadoop/etc/hadoop/mapred-site.xml
            - ./config/hdfs-spark/common/yarn-site.xml:/workspace/hadoop/etc/hadoop/yarn-site.xml
            - ./src:/workspace/src
            - ./scripts/namenode-entrypoint.sh:/workspace/standby-namenode.sh
        depends_on:
            - datanode-nodemanager-1
            - datanode-nodemanager-2
            - datanode-nodemanager-3

    datanode-nodemanager-1:
        image: loind31/hdfs-spark:v0
        hostname: datanode-nodemanager-1
        container_name: datanode-nodemanager-1
        ports:
            - 8043:8042
        command: ["/bin/bash", "/workspace/datanode-entrypoint.sh"]
        volumes:
            - ./data/datanodes/datanode-1/local-data:/workspace/hadoop/dfs/data
            - ./data/datanodes/datanode-1/journal:/workspace/journalnode
            - ./config/hdfs-spark/spark-defaults.conf:/workspace/spark/conf/spark-defaults.conf
            - ./config/hdfs-spark/common/hdfs-site.xml:/workspace/hadoop/etc/hadoop/hdfs-site.xml
            - ./config/hdfs-spark/common/core-site.xml:/workspace/hadoop/etc/hadoop/core-site.xml
            - ./config/hdfs-spark/common/mapred-site.xml:/workspace/hadoop/etc/hadoop/mapred-site.xml
            - ./config/hdfs-spark/common/yarn-site.xml:/workspace/hadoop/etc/hadoop/yarn-site.xml
            - ./scripts/datanode-entrypoint.sh:/workspace/datanode-entrypoint.sh

    datanode-nodemanager-2:
        image: loind31/hdfs-spark:v0
        hostname: datanode-nodemanager-2
        container_name: datanode-nodemanager-2
        ports:
            - 8044:8042
        command: ["/bin/bash", "/workspace/datanode-entrypoint.sh"]
        volumes:
            - ./data/datanodes/datanode-2/local-data:/workspace/hadoop/dfs/data
            - ./data/datanodes/datanode-2/journal:/workspace/journalnode
            - ./config/hdfs-spark/spark-defaults.conf:/workspace/spark/conf/spark-defaults.conf
            - ./config/hdfs-spark/common/hdfs-site.xml:/workspace/hadoop/etc/hadoop/hdfs-site.xml
            - ./config/hdfs-spark/common/core-site.xml:/workspace/hadoop/etc/hadoop/core-site.xml
            - ./config/hdfs-spark/common/mapred-site.xml:/workspace/hadoop/etc/hadoop/mapred-site.xml
            - ./config/hdfs-spark/common/yarn-site.xml:/workspace/hadoop/etc/hadoop/yarn-site.xml
            - ./scripts/datanode-entrypoint.sh:/workspace/datanode-entrypoint.sh
            
    datanode-nodemanager-3:
        image: loind31/hdfs-spark:v0
        hostname: datanode-nodemanager-3
        container_name: datanode-nodemanager-3
        ports:
            - 8045:8042
        command: ["/bin/bash", "/workspace/datanode-entrypoint.sh"]
        volumes:
            - ./data/datanodes/datanode-3/local-data:/workspace/hadoop/dfs/data
            - ./data/datanodes/datanode-3/journal:/workspace/journalnode
            - ./config/hdfs-spark/spark-defaults.conf:/workspace/spark/conf/spark-defaults.conf
            - ./config/hdfs-spark/common/hdfs-site.xml:/workspace/hadoop/etc/hadoop/hdfs-site.xml
            - ./config/hdfs-spark/common/core-site.xml:/workspace/hadoop/etc/hadoop/core-site.xml
            - ./config/hdfs-spark/common/mapred-site.xml:/workspace/hadoop/etc/hadoop/mapred-site.xml
            - ./config/hdfs-spark/common/yarn-site.xml:/workspace/hadoop/etc/hadoop/yarn-site.xml
            - ./scripts/datanode-entrypoint.sh:/workspace/datanode-entrypoint.sh